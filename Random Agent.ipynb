{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Agent \n",
    "\n",
    "This is a random agent as implemented in examples provided [here](https://gitlab.aicrowd.com/flatland/flatland/blob/master/examples/training_example.py) by the Flatland challenge creators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from flatland.envs.observations import TreeObsForRailEnv, LocalObsForRailEnv\n",
    "from flatland.envs.predictions import ShortestPathPredictorForRailEnv\n",
    "from flatland.envs.rail_env import RailEnv\n",
    "from flatland.envs.rail_generators import complex_rail_generator\n",
    "from flatland.envs.schedule_generators import complex_schedule_generator\n",
    "from flatland.utils.rendertools import RenderTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "# Use the complex_rail_generator to generate feasible network configurations with corresponding tasks\n",
    "# Training on simple small tasks is the best way to get familiar with the environment\n",
    "N_agents = 1\n",
    "#max_dist=99999\n",
    "max_dist=50\n",
    "\n",
    "TreeObservation = TreeObsForRailEnv(max_depth=2, predictor=ShortestPathPredictorForRailEnv())\n",
    "LocalGridObs = LocalObsForRailEnv(view_height=10, view_width=2, center=2)\n",
    "rail_generator = complex_rail_generator(nr_start_goal=10, nr_extra=2, min_dist=8, max_dist=max_dist, seed=1)\n",
    "env = RailEnv(width=20, height=20,\n",
    "              rail_generator= rail_generator,\n",
    "              schedule_generator=complex_schedule_generator(), \n",
    "              number_of_agents=N_agents, \n",
    "              obs_builder_object=TreeObservation)\n",
    "env.reset()\n",
    "\n",
    "env_renderer = RenderTool(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your own Agent or use RLlib to train agents on Flatland\n",
    "# As an example we use a random agent here\n",
    "class RandomAgent:\n",
    "\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"\n",
    "        :param state: input is the observation of the agent\n",
    "        :return: returns an action\n",
    "        \"\"\"\n",
    "        return np.random.choice(np.arange(self.action_size))\n",
    "\n",
    "    def step(self, memories):\n",
    "        \"\"\"\n",
    "        Step function to improve agent by adjusting policy given the observations\n",
    "\n",
    "        :param memories: SARS Tuple to be\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    def save(self, filename):\n",
    "        # Store the current policy\n",
    "        return\n",
    "\n",
    "    def load(self, filename):\n",
    "        # Load a policy\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n"
     ]
    }
   ],
   "source": [
    "# Initialize the agent with the parameters corresponding to the environment and observation_builder\n",
    "agent = RandomAgent(218, 5)\n",
    "n_trials = 20\n",
    "\n",
    "# Empty dictionary for all agent action\n",
    "action_dict = dict()\n",
    "print(\"Starting Training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode Nr. 20\t Score = -33.0"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "for trials in range(1, n_trials + 1):\n",
    "\n",
    "    # Reset environment and get initial observations for all agents\n",
    "    obs, info = env.reset()\n",
    "    for idx in range(env.get_num_agents()):\n",
    "        tmp_agent = env.agents[idx]\n",
    "        tmp_agent.speed_data[\"speed\"] = 1 / (idx + 1)\n",
    "    env_renderer.reset()\n",
    "    # Here you can also further enhance the provided observation by means of normalization\n",
    "    # See training navigation example in the baseline repository\n",
    "\n",
    "    score = 0\n",
    "    # Run episode\n",
    "    for step in range(50):\n",
    "        # Chose an action for each agent in the environment\n",
    "        for a in range(env.get_num_agents()):\n",
    "            action = agent.act(obs[a])\n",
    "            action_dict.update({a: action})\n",
    "        # Environment step which returns the observations for all agents, their corresponding\n",
    "        # reward and whether their are done\n",
    "        next_obs, all_rewards, done, _ = env.step(action_dict)\n",
    "        # note that rendering significantly slows down the average run time\n",
    "        # consider commenting the rendering command for a faster run\n",
    "        # env_renderer.render_env(show=True, show_observations=True, show_predictions=False)\n",
    "\n",
    "        # Update replay buffer and train agent\n",
    "        for a in range(env.get_num_agents()):\n",
    "            agent.step((obs[a], action_dict[a], all_rewards[a], next_obs[a], done[a]))\n",
    "            score += all_rewards[a]\n",
    "        obs = next_obs.copy()\n",
    "        if done['__all__']:\n",
    "            break\n",
    "    all_scores.append(score)        \n",
    "    print('\\rEpisode Nr. {}\\t Score = {}'.format(trials, score), end = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average score of a random agent over 20 episodes is -43.6\n"
     ]
    }
   ],
   "source": [
    "avg = np.mean(all_scores)\n",
    "print('average score of a random agent over {} episodes is {}'.format(n_trials, avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Agent with renderer without background embellishments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to check that the renderer works fine even after removing background embellishments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "from collections import deque\n",
    "#import tkinter as tk\n",
    "\n",
    "from flatland.envs.observations import TreeObsForRailEnv, LocalObsForRailEnv\n",
    "from flatland.envs.predictions import ShortestPathPredictorForRailEnv\n",
    "from flatland.envs.rail_env import RailEnv\n",
    "from flatland.envs.rail_generators import complex_rail_generator\n",
    "from flatland.envs.schedule_generators import complex_schedule_generator\n",
    "from flatland.utils.rendertools import RenderTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from numpy import array\n",
    "from pkg_resources import resource_string as resource_bytes\n",
    "\n",
    "from flatland.utils.graphics_layer import GraphicsLayer\n",
    "\n",
    "from flatland.core.grid.rail_env_grid import RailEnvTransitions \n",
    "\n",
    "from flatland.utils.graphics_pil import PILGL, PILSVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "# Use the complex_rail_generator to generate feasible network configurations with corresponding tasks\n",
    "# Training on simple small tasks is the best way to get familiar with the environment\n",
    "N_agents = 1\n",
    "\n",
    "TreeObservation = TreeObsForRailEnv(max_depth=2, predictor=ShortestPathPredictorForRailEnv())\n",
    "LocalGridObs = LocalObsForRailEnv(view_height=10, view_width=2, center=2)\n",
    "rail_generator = complex_rail_generator(nr_start_goal=10, nr_extra=2, min_dist=8, max_dist=99999, seed=1)\n",
    "env = RailEnv(width=20, height=20,\n",
    "              rail_generator= rail_generator,\n",
    "              schedule_generator=complex_schedule_generator(), \n",
    "              number_of_agents=N_agents, \n",
    "              obs_builder_object=TreeObservation)\n",
    "env.reset()\n",
    "\n",
    "env_renderer = RenderTool(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_rail_at_new(self, row, col, binary_trans, target=None, is_selected=False, rail_grid=None, num_agents=None,\n",
    "                show_debug=True):\n",
    "    \n",
    "    if binary_trans in self.pil_rail:\n",
    "        pil_track = self.pil_rail[binary_trans]\n",
    "        if target is not None:\n",
    "            target_img = self.station_colors[target % len(self.station_colors)]\n",
    "            target_img = Image.alpha_composite(pil_track, target_img)\n",
    "            self.draw_image_row_col(target_img, (row, col), layer=PILGL.TARGET_LAYER)\n",
    "            if show_debug:\n",
    "                self.text_rowcol((row + 0.8, col + 0.0), strText=str(target), layer=PILGL.TARGET_LAYER)\n",
    "\n",
    "        city_size = 1\n",
    "        if num_agents is not None:\n",
    "            city_size = max(1, np.log(1 + num_agents) / 2.5)\n",
    "\n",
    "        self.draw_image_row_col(pil_track, (row, col), layer=PILGL.RAIL_LAYER)\n",
    "    else:\n",
    "        print(\"Illegal rail:\", row, col, format(binary_trans, \"#018b\")[2:], binary_trans)\n",
    "\n",
    "    if target is not None:\n",
    "        if is_selected:\n",
    "            svgBG = self.pil_from_png_file('flatland.png', \"Selected_Target.png\")\n",
    "            self.clear_layer(PILGL.SELECTED_TARGET_LAYER, 0)\n",
    "            self.draw_image_row_col(svgBG, (row, col), layer=PILGL.SELECTED_TARGET_LAYER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcType = types.MethodType\n",
    "env_renderer = RenderTool(env)\n",
    "env_renderer.gl.set_rail_at = funcType(set_rail_at_new, env_renderer.gl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your own Agent or use RLlib to train agents on Flatland\n",
    "# As an example we use a random agent here\n",
    "class RandomAgent:\n",
    "\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"\n",
    "        :param state: input is the observation of the agent\n",
    "        :return: returns an action\n",
    "        \"\"\"\n",
    "        return np.random.choice(np.arange(self.action_size))\n",
    "\n",
    "    def step(self, memories):\n",
    "        \"\"\"\n",
    "        Step function to improve agent by adjusting policy given the observations\n",
    "\n",
    "        :param memories: SARS Tuple to be\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    def save(self, filename):\n",
    "        # Store the current policy\n",
    "        return\n",
    "\n",
    "    def load(self, filename):\n",
    "        # Load a policy\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n"
     ]
    }
   ],
   "source": [
    "# Initialize the agent with the parameters corresponding to the environment and observation_builder\n",
    "agent = RandomAgent(218, 5)\n",
    "n_trials = 5000\n",
    "\n",
    "# Empty dictionary for all agent action\n",
    "action_dict = dict()\n",
    "print(\"Starting Training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode Nr. 5000\tScore = -150.0\tAverage Score: -102.31"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "scores_window = deque(maxlen = 100) # scores of last 100 episodes\n",
    "for trials in range(1, n_trials + 1):\n",
    "\n",
    "    # Reset environment and get initial observations for all agents\n",
    "    obs, info = env.reset()\n",
    "    for idx in range(env.get_num_agents()):\n",
    "        tmp_agent = env.agents[idx]\n",
    "        tmp_agent.speed_data[\"speed\"] = 1 / (idx + 1)\n",
    "    env_renderer.reset()\n",
    "    # Here you can also further enhance the provided observation by means of normalization\n",
    "    # See training navigation example in the baseline repository\n",
    "\n",
    "    score = 0\n",
    "    # Run episode\n",
    "    for step in range(150):\n",
    "        # Chose an action for each agent in the environment\n",
    "        for a in range(env.get_num_agents()):\n",
    "            action = agent.act(obs[a])\n",
    "            action_dict.update({a: action})\n",
    "        # Environment step which returns the observations for all agents, their corresponding\n",
    "        # reward and whether their are done\n",
    "        next_obs, all_rewards, done, _ = env.step(action_dict)\n",
    "        # note that rendering significantly slows down the average run time\n",
    "        # consider commenting the rendering command for a faster run\n",
    "        # env_renderer.render_env(show=True, show_observations=True, show_predictions=False)\n",
    "\n",
    "        # Update replay buffer and train agent\n",
    "        for a in range(env.get_num_agents()):\n",
    "            agent.step((obs[a], action_dict[a], all_rewards[a], next_obs[a], done[a]))\n",
    "            score += all_rewards[a]\n",
    "        obs = next_obs.copy()\n",
    "        if done['__all__']:\n",
    "            break\n",
    "    all_scores.append(score)\n",
    "    scores_window.append(score)\n",
    "    print('\\rEpisode Nr. {}\\tScore = {}\\tAverage Score: {:.2f}'.format(trials, score, np.mean(scores_window)), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average score of a random agent over 5000 episodes is -104.5528\n"
     ]
    }
   ],
   "source": [
    "avg = np.mean(all_scores)\n",
    "print('average score of a random agent over {} episodes is {}'.format(n_trials, avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(1,len(all_scores)+1), all_scores )\n",
    "plt.xlabel(\"Episode no.\")\n",
    "plt.ylabel(\"Episode score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to work fine!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:flatland-rl]",
   "language": "python",
   "name": "conda-env-flatland-rl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
